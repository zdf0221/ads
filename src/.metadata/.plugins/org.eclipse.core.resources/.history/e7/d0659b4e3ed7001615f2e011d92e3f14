package wu.leizi.project.offline;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.Iterator;

import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.sql.SparkSession;

import wu.leizi.Driver.HeartBeat.HBClientDriver;
import wu.leizi.config.HDFSConfig;
import wu.leizi.config.sparkConfig;
import org.json.*;

import scala.Tuple2;
public class offlineBehaviorTarget implements Serializable {
	/**
	 * 
	 */
	private static final long serialVersionUID = 1L;
	private boolean isRunning;
	public offlineBehaviorTarget(String id) {
		// TODO Auto-generated constructor stub
		isRunning = false;
	}
	public void offlineBT() {
		isRunning = true;
		
		SparkSession sc = sparkConfig.getInstance().getSs();
		JavaRDD<String> click = sc.read().textFile((HDFSConfig.getInstance().getClickUrl())).toJavaRDD();
		JavaRDD<String> keys = click.flatMap(new FlatMapFunction<String, String>() {
			@Override
			public Iterator<String> call(String s) throws Exception {
				// TODO Auto-generated method stub
				System.out.println(s);
				JSONObject ans = new JSONObject(s);
				String cookieId = ans.getString("cookieId ");
				ArrayList<String> types = new ArrayList<String>();
				for (String t : ans.getString("type").split("[-]")) {
					types.add(cookieId + "-" + t);
				}
				return types.iterator();
			}
		});
		JavaPairRDD<String, Integer> ones = keys.mapToPair(new PairFunction<String, String, Integer>() {

			@Override
			public Tuple2<String, Integer> call(String s) throws Exception {
				// TODO Auto-generated method stub
				return new Tuple2<String, Integer>(s, 1);
			}
		});
		JavaPairRDD<String, Integer> counts = ones.reduceByKey((x, y) -> x+y);
		for (Tuple2<String, Integer> p : counts.collect()) {
			System.out.println(p._1() + ":" + p._2());
		}
	}
}