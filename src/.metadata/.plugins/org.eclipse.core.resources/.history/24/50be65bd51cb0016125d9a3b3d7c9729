package wu.leizi.Driver.offline;

import java.util.Properties;

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.Row;
import wu.leizi.Driver.heartbeat.HBClientDriver;
import wu.leizi.config.HDFSConfig;
import wu.leizi.config.sparkConfig;
import org.apache.spark.sql.SaveMode;

public class adsStatisDriver extends HBClientDriver {
	private boolean isRunning;
	public adsStatisDriver(String id) {
		super("AdsStaticsDriver"+id);
		isRunning = true;
		// TODO Auto-generated constructor stub
		
	}
	
	public void start() {
    	super.put(); 
    }
    
	public void ctrStatis() throws InterruptedException {
		SparkSession sc = sparkConfig.getInstance().getSc();
		Dataset<Row> click = sc.read().json(HDFSConfig.getInstance().getClickUrl());
		Dataset<Row> put = sc.read().json(HDFSConfig.getInstance().getBidUrl());
		Dataset<Row> ans = click.join(put, click.col("putId").equalTo(put.col("id")), "outer");
//		ans.select(put.col("id").as("putId"), put.col("adsId"), click.col("adsId").as("label")).show();
		Dataset<Row> a = ans.select(put.col("adsId"), click.col("adsId")).groupBy(put.col("adsId").as("id"),click.col("adsId").as("label")).count();
		Dataset<Row> b = ans.select(put.col("adsId"), click.col("adsId")).groupBy(put.col("adsId").as("id")).count();
		a.createOrReplaceTempView("a");
		b.createOrReplaceTempView("b");
		Thread.sleep(2000);
		Dataset<Row> ret=sc.sql("select a.id, a.count as click, b.count as total from a,b where a.id=b.id and not a.label=NULL");
		ret.show();
		String MYSQL_CONNECTION_URL
		ret.write().mode(SaveMode.Overwrite).jdbc(MYSQL_CONNECTION_URL, "record", connectionProperties);
	}
	
	public void close() {
		super.endService();
		
	}
	
    public String ServiceStatus() {
		return super.ServiceStatus() + " ads Statis Service:" + isRunning;
	}
	
	
}
